# ğŸ¤– Local RAG AI - Tu Consultor Privado de Manuales

[![Ollama](https://img.shields.io/badge/LLM-Ollama-blue.svg)](https://ollama.com/)
[![Python](https://img.shields.io/badge/Python-3.10%2B-green.svg)](https://www.python.org/)
[![Interfaz](https://img.shields.io/badge/Interfaz-Glassmorphism-purple.svg)](#)
[![Licencia: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

Un sistema de GeneraciÃ³n Aumentada por RecuperaciÃ³n (RAG) de alto rendimiento, **100% privado** y local. Chatea con tus manuales tÃ©cnicos (PDFs) sin necesidad de conexiÃ³n a internet, utilizando modelos de cÃ³digo abierto de Ãºltima generaciÃ³n.

![PrevisualizaciÃ³n del Proyecto](https://via.placeholder.com/800x450.png?text=Interfaz+RAG+Local+Preview)

## âœ¨ CaracterÃ­sticas

- ğŸ”’ **Privacidad Total**: Todo se ejecuta en tu mÃ¡quina. NingÃºn dato sale de tu red local.
- âš¡ **Modelos IA**: Potenciado por **Llama 3.2** (Inteligencia) y **Nomic Embed Text** (Contexto).
- ğŸ¨ **Interfaz Premium**: DiseÃ±o moderno con efecto "Glassmorphism", modo oscuro y animaciones fluidas.
- ğŸ“‚ **GestiÃ³n de Documentos**: Sube y re-indexa mÃºltiples manuales PDF directamente desde la web.
- ğŸ“ **Transparencia en Fuentes**: Citas precisas de los documentos y pÃ¡ginas donde se encontrÃ³ la informaciÃ³n.
- ğŸ—ï¸ **FragmentaciÃ³n Inteligente**: Procesamiento avanzado de texto para una recuperaciÃ³n de informaciÃ³n exacta.

## ğŸ› ï¸ TecnologÃ­as

- **Backend**: FastAPI (Python)
- **Frontend**: HTML5, Tailwind CSS, Lucide Icons
- **Framework RAG**: LangChain
- **Base de Datos Vectorial**: ChromaDB
- **Motor LLM**: Ollama

## ğŸš€ Primeros Pasos

### 1. Requisitos previos
- Instala [Ollama](https://ollama.com/)
- Descarga los modelos necesarios:
  ```bash
  ollama pull llama3.2
  ollama pull nomic-embed-text
  ```

### 2. InstalaciÃ³n
Clona el repositorio e instala las dependencias:
```bash
git clone https://github.com/nardet30/sistema-rag-local.git
cd sistema-rag-local
pip install -r requirements.txt
```

### 3. Uso
1. Inicia el servidor:
   ```bash
   python app.py
   ```
2. Abre tu navegador en [http://localhost:8000](http://localhost:8000).
3. Sube tus manuales PDF a travÃ©s de la interfaz y pulsa el botÃ³n de **Re-indexar**.

## ğŸ“‚ Estructura del Proyecto

```text
â”œâ”€â”€ app.py             # Servidor FastAPI y Endpoints de la API
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ rag_engine.py  # LÃ³gica Central: Embeddings, RecuperaciÃ³n y Cadena LLM
â”‚   â””â”€â”€ config.py      # Configuraciones del Sistema
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html     # Interfaz Web Premium
â”œâ”€â”€ data/              # Carpeta de almacenamiento de tus PDFs
â””â”€â”€ vector_db_local/   # Almacenamiento persistente de la base de datos vectorial
```

## ğŸŒ GitHub Pages (PresentaciÃ³n)
Visita nuestra [Landing Page](https://nardet30.github.io/sistema-rag-local/) para ver el diseÃ±o de la interfaz y sus capacidades.

## ğŸ¤ Contribuciones
SiÃ©ntete libre de abrir issues o enviar pull requests. Â¡Cualquier mejora en velocidad o experiencia de usuario es bienvenida!

---
Desarrollado con â¤ï¸ por [nardet](https://github.com/nardet30)
